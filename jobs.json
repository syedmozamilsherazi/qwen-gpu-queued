{
  "queue": [
    {
      "id": "b95a34b7-8389-42d8-9142-0d885631c290",
      "messages": [
        {
          "content": "You are a systematic literature review (SLR) screening assistant.\n\n\nDOMAIN: AI/ML/DL applications in ophthalmology and eye diseases.\n\nRELEVANT DISEASES:\n- Diabetic Retinopathy\n- Glaucoma\n- Cataract\n- Age-related Macular Degeneration (AMD)\n- Retinal disorders (retinopathy, retinal detachment, etc.)\n- Ophthalmic conditions (keratoconus, dry eye, etc.)\n- Any eye/vision-related diseases\n\nRELEVANT TASKS:\n- Diagnosis\n- Detection\n- Classification\n- Severity grading\n- Prediction\n- Segmentation\n- Screening\n\nRELEVANT METHODS:\n- Artificial Intelligence (AI)\n- Machine Learning (ML)\n- Deep Learning (DL)\n- Neural Networks (CNN, RNN, Transformers, etc.)\n- Computer Vision\n- Image Analysis\n\n\n================================================================================\nTASK: Evaluate this paper ABSTRACT for inclusion.\n(This paper passed title screening)\n================================================================================\n\nTITLE: Multi-Task Collaborative Learning for Robust Diabetic Retinopathy Grading on Low-Quality Fundus Images\nABSTRACT: Diabetic retinopathy (DR) is a major cause of vision loss in working-age individuals, and automated detection systems can assist clinicians in early diagnosis and treatment. However, existing grading methods trained on high-quality fundus images often exhibit significant performance degradation when applied to low-quality images commonly encountered in clinical practice. To address this issue, we propose IELS-DR, a multi-task collaborative learning framework specifically designed for low-quality fundus images. The framework jointly optimizes three tasks: image enhancement, lesion segmentation, and lesion severity classification. It incorporates a dedicated image enhancement subnet tailored for low-quality images to improve clarity and facilitate downstream tasks. Additionally, we introduce a Cross-task Feature Aggregation (CFA) module, which employs a cross-task, multi-scale CNN architecture to enable deep feature sharing and interaction between lesion segmentation and DR classification tasks. The CFA module enhances multi-scale feature fusion, strengthens lesion feature representation, and promotes effective task collaboration. Experiments on the DDR dataset show that IELS-DR delivers leading performance, with an accuracy of 86.61\\%, precision of 83.57\\%, kappa of 82.36\\%, recall of 85.09\\%, and F1-score of 84.25\\%. Furthermore, it delivers competitive results in image enhancement and lesion segmentation tasks. Ablation studies confirm the efficacy of the proposed framework and CFA module in improving robustness for low-quality image analysis and DR grading.\n\n================================================================================\nSELECTION RULES (BE INCLUSIVE - DO NOT MISS RELEVANT PAPERS):\n================================================================================\n\nOUTPUT: Abstract_Selected\nIF ANY of the following is TRUE:\n- Abstract confirms AI/ML/DL method for eye disease\n- Abstract describes automated diagnosis/detection for ophthalmology\n- Abstract mentions dataset of retinal/fundus/OCT images with ML analysis\n- Abstract is UNCLEAR but suggests AI application in eye care\n- Abstract describes deep learning model for any eye condition\n\nOUTPUT: Abstract_Deleted\nONLY IF the abstract CLEARLY confirms:\n- This is a review/survey/meta-analysis paper (not primary research)\n- No AI/ML/DL methodology is used at all\n- The disease is NOT eye-related\n- The paper is editorial/commentary/opinion only\n\n================================================================================\nIMPORTANT: When abstract is missing or unclear, SELECT (Abstract_Selected).\nWe prefer false positives over missing relevant papers.\n================================================================================\n\nOUTPUT: Respond with EXACTLY one label only (no explanation):\nAbstract_Selected\nOR\nAbstract_Deleted\n\nYOUR RESPONSE:",
          "role": "user"
        }
      ],
      "max_tokens": 256
    }
  ]
}