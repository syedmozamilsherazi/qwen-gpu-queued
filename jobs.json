{
  "queue": [
    {
      "id": "b292d33d-4e77-414f-b5f2-0ac29a34fc79",
      "messages": [
        {
          "content": "You are a systematic literature review (SLR) screening assistant.\n\n\nDOMAIN: AI/ML/DL applications in ophthalmology and eye diseases.\n\nRELEVANT DISEASES:\n- Diabetic Retinopathy\n- Glaucoma\n- Cataract\n- Age-related Macular Degeneration (AMD)\n- Retinal disorders (retinopathy, retinal detachment, etc.)\n- Ophthalmic conditions (keratoconus, dry eye, etc.)\n- Any eye/vision-related diseases\n\nRELEVANT TASKS:\n- Diagnosis\n- Detection\n- Classification\n- Severity grading\n- Prediction\n- Segmentation\n- Screening\n\nRELEVANT METHODS:\n- Artificial Intelligence (AI)\n- Machine Learning (ML)\n- Deep Learning (DL)\n- Neural Networks (CNN, RNN, Transformers, etc.)\n- Computer Vision\n- Image Analysis\n\n\n================================================================================\nTASK: Evaluate this paper ABSTRACT for inclusion.\n(This paper passed title screening)\n================================================================================\n\nTITLE: Contextual Self-Attention Based UNet Architecture for Fluid Segmentation in Retinal OCT B-scans\nABSTRACT: Retinal edema caused by fluid buildups has links to vision threatening retinal diseases. Presently, spectral-domain optical coherence tomography (SD-OCT) is the imaging method of choice for evaluating retinal health and tracking treatment progress. Automated methods for fluid segmentation in retinal OCT B-scans are critical for ocular disease diagnosis. The segmentation task in retinal OCT B-scans with pathological manifestations is challenging as the retinal layered structure varies significantly with the severity of the underlying disease condition. In this paper, we present a Contextual Self-Attention based U-Net (CoSAUNet) architecture for fluid segmentation in pathological OCT B-scans. The proposed model replaces the basic convolutional layers in the standard U-Net architecture with contextual self-attention layers. The contextual self-attention mechanism integrates contextual information mining among neighboring keys and conventional self-attention into a unified architecture to learn the long-range feature dependencies. The robustness of the proposed CoSAUNet model is evaluated through a 3-fold cross-validation setup on the RETOUCH and the AROI datasets, yielding average Dice scores (DS) of 88.16\\% and 76.67\\%, respectively. Furthermore, the CoSAUNet performs comparably to the state-of-the-art methods while using only half of the parameters.\n\n================================================================================\nSELECTION RULES (BE INCLUSIVE - DO NOT MISS RELEVANT PAPERS):\n================================================================================\n\nOUTPUT: Abstract_Selected\nIF ANY of the following is TRUE:\n- Abstract confirms AI/ML/DL method for eye disease\n- Abstract describes automated diagnosis/detection for ophthalmology\n- Abstract mentions dataset of retinal/fundus/OCT images with ML analysis\n- Abstract is UNCLEAR but suggests AI application in eye care\n- Abstract describes deep learning model for any eye condition\n\nOUTPUT: Abstract_Deleted\nONLY IF the abstract CLEARLY confirms:\n- This is a review/survey/meta-analysis paper (not primary research)\n- No AI/ML/DL methodology is used at all\n- The disease is NOT eye-related\n- The paper is editorial/commentary/opinion only\n\n================================================================================\nIMPORTANT: When abstract is missing or unclear, SELECT (Abstract_Selected).\nWe prefer false positives over missing relevant papers.\n================================================================================\n\nOUTPUT: Respond with EXACTLY one label only (no explanation):\nAbstract_Selected\nOR\nAbstract_Deleted\n\nYOUR RESPONSE:",
          "role": "user"
        }
      ],
      "max_tokens": 256
    }
  ]
}