{
  "queue": [
    {
      "id": "3be575b2-b600-4140-a04a-20b51007d40c",
      "messages": [
        {
          "content": "You are a systematic literature review (SLR) screening assistant.\nYour job is to BE INCLUSIVE - we must NOT miss any relevant papers about AI/ML for eye diseases.\n\n\nDOMAIN: AI/ML/DL applications in ophthalmology and eye diseases.\n\nRELEVANT EYE DISEASES (SELECT if ANY mentioned):\n- Diabetic Retinopathy (DR)\n- Glaucoma\n- Cataract\n- Age-related Macular Degeneration (AMD/ARMD)\n- Retinal disorders (retinopathy, retinal detachment, macular edema, etc.)\n- Ophthalmic conditions (keratoconus, dry eye, conjunctivitis, etc.)\n- Retinal vessel diseases\n- Optic nerve disorders\n- Corneal diseases\n- ANY eye/vision/ocular/ophthalmic disease or condition\n\nRELEVANT TASKS (SELECT if ANY mentioned):\n- Diagnosis / Detection / Identification\n- Classification / Grading / Staging\n- Prediction / Prognosis\n- Segmentation (pixel-based, semantic, instance, etc.)\n- Screening / Triage\n- Image Analysis / Feature Extraction\n- Lesion Detection / Localization\n- Automated / Computer-aided analysis\n\nRELEVANT AI/ML METHODS (SELECT if ANY mentioned):\n- Artificial Intelligence (AI)\n- Machine Learning (ML)\n- Deep Learning (DL)\n- Neural Networks (CNN, RNN, LSTM, Transformers, U-Net, ResNet, VGG, etc.)\n- Computer Vision\n- Image Processing / Analysis\n- Segmentation (pixel-based, semantic, watershed, region-based, etc.)\n- Feature Extraction / Selection\n- Pattern Recognition\n- Automated / Computerized methods\n- Transfer Learning\n- Ensemble methods\n- Support Vector Machines (SVM)\n- Random Forest\n- K-Nearest Neighbors\n- Convolutional methods\n- Attention mechanisms\n- ANY computational/algorithmic approach to medical image analysis\n\n\n================================================================================\nTASK: Evaluate this paper ABSTRACT for inclusion.\n(This paper already passed title screening - it likely IS relevant)\n================================================================================\n\nTITLE: Non-Invasive to Invasive: Enhancing FFA Synthesis from CFP with a Benchmark Dataset and a Novel Network\nABSTRACT: Fundus imaging is a pivotal tool in ophthalmology, and different imaging modalities are characterized by their specific advantages. For example, Fundus Fluorescein Angiography (FFA) uniquely provides detailed insights into retinal vascular dynamics and pathology, surpassing Color Fundus Photographs (CFP) in detecting microvascular abnormalities and perfusion status. However, the conventional invasive FFA involves discomfort and risks due to fluorescein dye injection, and it is meaningful but challenging to synthesize FFA images from non-invasive CFP. Previous studies primarily focused on FFA synthesis in a single disease category. In this work, we explore FFA synthesis in multiple diseases by devising a Diffusion-guided generative adversarial network, which introduces an adaptive and dynamic diffusion forward process into the discriminator and adds a category-aware representation enhancer. Moreover, to facilitate this research, we collect the first multi-disease CFP and FFA paired dataset, named the Multi-disease Paired Ocular Synthesis (MPOS) dataset, with four different fundus diseases. Experimental results show that our FFA synthesis network can generate better FFA images compared to state-of-the-art methods. Furthermore, we introduce a paired-modal diagnostic network to validate the effectiveness of synthetic FFA images in the diagnosis of multiple fundus diseases, and the results show that our synthesized FFA images with the real CFP images have higher diagnosis accuracy than that of the compared FFA synthesizing methods. Our research bridges the gap between non-invasive imaging and FFA, thereby offering promising prospects to enhance ophthalmic diagnosis and patient care, with a focus on reducing harm to patients through non-invasive procedures. Our dataset and code will be released to support further research in this field (https://github.com/whq-xxh/FFA-Synthesis).\n\n================================================================================\nSELECTION RULES - BE VERY INCLUSIVE:\n================================================================================\n\nOUTPUT: Abstract_Selected\nIF ANY of the following is TRUE:\n- Abstract mentions ANY eye disease (diabetic retinopathy, glaucoma, cataract, AMD, retinal, macular, etc.)\n- Abstract mentions ANY AI/ML technique (neural network, deep learning, segmentation, classification, detection, CNN, etc.)\n- Abstract describes automated/computerized analysis of eye images\n- Abstract mentions fundus images, OCT scans, retinal images, or ophthalmic imaging\n- Abstract describes segmentation, feature extraction, or pixel-based analysis for eye disease\n- Abstract discusses diagnosis, detection, classification, grading, or prediction of eye conditions\n- Abstract mentions dataset of eye/retinal/fundus images\n- Abstract is about computer-aided diagnosis for ophthalmology\n- Abstract is UNCLEAR but the title suggests relevance\n- Abstract is MISSING (select by default)\n\nOUTPUT: Abstract_Deleted\nONLY IF the abstract CLEARLY AND EXPLICITLY confirms ALL of these:\n- This is ONLY a review/survey/meta-analysis paper (not original research) AND\n- NO AI/ML/DL methodology is actually used or proposed AND\n- The focus is NOT on eye diseases at all\n\n================================================================================\nCRITICAL EXAMPLES:\n- \"Pixel-based segmentation for diabetic retinopathy\" = Abstract_Selected\n  (Segmentation IS an AI/image processing technique!)\n- \"Automated identification using feature extraction\" = Abstract_Selected\n  (Automated + feature extraction = computational/AI approach!)\n- \"Deep learning for retinal vessel segmentation\" = Abstract_Selected\n- \"CNN-based classification of fundus images\" = Abstract_Selected\n================================================================================\n\nOUTPUT (one word only):\nAbstract_Selected\nOR\nAbstract_Deleted\n\nYOUR RESPONSE:",
          "role": "user"
        }
      ],
      "max_tokens": 256
    }
  ]
}