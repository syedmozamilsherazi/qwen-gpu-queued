{
  "queue": [
    {
      "id": "f22fcd11-0cb4-4bf3-8218-856f04f1540d",
      "messages": [
        {
          "content": "You are a systematic literature review (SLR) screening assistant.\n\n\nDOMAIN: AI/ML/DL applications in ophthalmology and eye diseases.\n\nRELEVANT DISEASES:\n- Diabetic Retinopathy\n- Glaucoma\n- Cataract\n- Age-related Macular Degeneration (AMD)\n- Retinal disorders (retinopathy, retinal detachment, etc.)\n- Ophthalmic conditions (keratoconus, dry eye, etc.)\n- Any eye/vision-related diseases\n\nRELEVANT TASKS:\n- Diagnosis\n- Detection\n- Classification\n- Severity grading\n- Prediction\n- Segmentation\n- Screening\n\nRELEVANT METHODS:\n- Artificial Intelligence (AI)\n- Machine Learning (ML)\n- Deep Learning (DL)\n- Neural Networks (CNN, RNN, Transformers, etc.)\n- Computer Vision\n- Image Analysis\n\n\n================================================================================\nTASK: Evaluate this paper ABSTRACT for inclusion.\n(This paper passed title screening)\n================================================================================\n\nTITLE: Application of vision transformers in the early detection of excavation in the BRSET base\nABSTRACT: Enlarged excavation of the optic papilla, caused by the loss of fibres that originate in the retina and transmit electrical stimuli to the visual cortex, is a critical indicator in the early detection of glaucoma, a disease that can lead to irreversible blindness. As the optic papilla shows morphological variations in the population, its identification can be a challenge. Methods based on deep learning have shown promise in helping doctors analyse these images more accurately. Recently, models such as Vision Transformers (ViT) have shown significant results in various medical applications, including glaucoma detection. However, the scarcity of quality data remains a major obstacle to training these models. This study evaluated the performance of the Swin Transformer, DeiT and Linformer models in detecting optic papilla excavation, using the new Brazilian Multilabel Ophthalmological Dataset (BRSET). The results showed that the DeiT model obtained the best accuracy, with 0.94, followed by the Swin Transformer, with 0.88, and the Linformer, with 0.85. The findings of this study suggest that ViT models can not only significantly improve the detection of glaucomatous papillary excavation, but also strengthen Human-Machine Collaboration, promoting more effective interaction between doctors and automated systems in medical diagnosis.\n\n================================================================================\nSELECTION RULES (BE INCLUSIVE - DO NOT MISS RELEVANT PAPERS):\n================================================================================\n\nOUTPUT: Abstract_Selected\nIF ANY of the following is TRUE:\n- Abstract confirms AI/ML/DL method for eye disease\n- Abstract describes automated diagnosis/detection for ophthalmology\n- Abstract mentions dataset of retinal/fundus/OCT images with ML analysis\n- Abstract is UNCLEAR but suggests AI application in eye care\n- Abstract describes deep learning model for any eye condition\n\nOUTPUT: Abstract_Deleted\nONLY IF the abstract CLEARLY confirms:\n- This is a review/survey/meta-analysis paper (not primary research)\n- No AI/ML/DL methodology is used at all\n- The disease is NOT eye-related\n- The paper is editorial/commentary/opinion only\n\n================================================================================\nIMPORTANT: When abstract is missing or unclear, SELECT (Abstract_Selected).\nWe prefer false positives over missing relevant papers.\n================================================================================\n\nOUTPUT: Respond with EXACTLY one label only (no explanation):\nAbstract_Selected\nOR\nAbstract_Deleted\n\nYOUR RESPONSE:",
          "role": "user"
        }
      ],
      "max_tokens": 256
    }
  ]
}